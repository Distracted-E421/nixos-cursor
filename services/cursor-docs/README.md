# cursor-docs - Local Documentation Indexing Service

> **Reliable, local alternative to Cursor's broken @docs system**

## ğŸ¯ Purpose

Cursor's built-in `@docs` feature relies on server-side crawling that fails ~50% of the time. This service provides a **local, reliable alternative** using:

- **Elixir** - Fault-tolerant, concurrent scraping with OTP supervision
- **Playwright** - Full JavaScript rendering (handles SPAs, React docs, etc.)
- **SurrealDB** - Local storage with full-text search and P2P sync capability
- **MCP Protocol** - Seamless integration with Cursor

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        cursor-docs Service                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    CursorDocs.Application                    â”‚   â”‚
â”‚  â”‚  (OTP Application - Supervised Process Tree)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                               â”‚                                     â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚           â–¼                   â–¼                   â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Scraper.Pool   â”‚ â”‚  Storage.Surrealâ”‚ â”‚  MCP.Server         â”‚   â”‚
â”‚  â”‚  (GenServer)    â”‚ â”‚  (GenServer)    â”‚ â”‚  (Plug/Cowboy)      â”‚   â”‚
â”‚  â”‚                 â”‚ â”‚                 â”‚ â”‚                     â”‚   â”‚
â”‚  â”‚  â€¢ Browser pool â”‚ â”‚  â€¢ Connection   â”‚ â”‚  â€¢ Tool handlers    â”‚   â”‚
â”‚  â”‚  â€¢ Job queue    â”‚ â”‚    management   â”‚ â”‚  â€¢ JSON-RPC         â”‚   â”‚
â”‚  â”‚  â€¢ Rate limits  â”‚ â”‚  â€¢ FTS queries  â”‚ â”‚  â€¢ Stdio transport  â”‚   â”‚
â”‚  â”‚  â€¢ Retry logic  â”‚ â”‚  â€¢ Sync events  â”‚ â”‚                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                   â”‚                     â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                               â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    SurrealDB (Embedded)                      â”‚   â”‚
â”‚  â”‚                                                              â”‚   â”‚
â”‚  â”‚  doc_sources: [id, url, title, status, pages_count, ...]    â”‚   â”‚
â”‚  â”‚  doc_chunks:  [id, source_id, url, content, position, ...]  â”‚   â”‚
â”‚  â”‚  scrape_jobs: [id, url, status, attempts, error, ...]       â”‚   â”‚
â”‚  â”‚                                                              â”‚   â”‚
â”‚  â”‚  FTS Index: DEFINE INDEX content_fts ON doc_chunks          â”‚   â”‚
â”‚  â”‚             FIELDS content SEARCH ANALYZER vs               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Project Structure

```
services/cursor-docs/
â”œâ”€â”€ mix.exs                    # Elixir project definition
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.exs             # Base configuration
â”‚   â”œâ”€â”€ dev.exs                # Development settings
â”‚   â””â”€â”€ prod.exs               # Production settings
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ cursor_docs.ex         # Application entry point
â”‚   â”œâ”€â”€ cursor_docs/
â”‚   â”‚   â”œâ”€â”€ application.ex     # OTP Application supervisor
â”‚   â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”‚   â”œâ”€â”€ pool.ex        # Browser pool management
â”‚   â”‚   â”‚   â”œâ”€â”€ worker.ex      # Individual scrape workers
â”‚   â”‚   â”‚   â”œâ”€â”€ job.ex         # Job queue management
â”‚   â”‚   â”‚   â””â”€â”€ extractor.ex   # Content extraction logic
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”‚   â”œâ”€â”€ surreal.ex     # SurrealDB client
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.ex      # Database schema definitions
â”‚   â”‚   â”‚   â””â”€â”€ search.ex      # Full-text search queries
â”‚   â”‚   â””â”€â”€ mcp/
â”‚   â”‚       â”œâ”€â”€ server.ex      # MCP protocol server
â”‚   â”‚       â”œâ”€â”€ tools.ex       # Tool definitions
â”‚   â”‚       â””â”€â”€ transport.ex   # Stdio/HTTP transport
â”œâ”€â”€ priv/
â”‚   â””â”€â”€ surreal/
â”‚       â””â”€â”€ schema.surql       # SurrealDB schema
â”œâ”€â”€ test/
â”‚   â””â”€â”€ cursor_docs_test.exs
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Elixir (via Nix)
nix-shell -p elixir erlang

# Or if using direnv with flake
cd services/cursor-docs
direnv allow
```

### Installation

```bash
cd services/cursor-docs

# Install dependencies
mix deps.get

# Setup database
mix cursor_docs.setup

# Start the service
mix cursor_docs.server
```

### CLI Usage

```bash
# Add documentation
mix cursor_docs.add https://docs.example.com/

# Add with custom name
mix cursor_docs.add https://hexdocs.pm/ecto/Ecto.html --name "Ecto Docs"

# List all indexed docs
mix cursor_docs.list

# Search documentation
mix cursor_docs.search "database queries"

# Check scrape job status
mix cursor_docs.status

# Remove documentation
mix cursor_docs.remove ecto-docs
```

### MCP Integration

Add to your Cursor MCP configuration (`~/.cursor/mcp.json`):

```json
{
  "mcpServers": {
    "cursor-docs": {
      "command": "mix",
      "args": ["cursor_docs.mcp"],
      "cwd": "/path/to/nixos-cursor/services/cursor-docs"
    }
  }
}
```

Then use in Cursor chat:

```
@cursor-docs search "how to define schemas"
@cursor-docs add https://docs.pola.rs/
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `CURSOR_DOCS_DB_PATH` | `~/.local/share/cursor-docs/` | SurrealDB data directory |
| `CURSOR_DOCS_BROWSER_POOL` | `3` | Concurrent browser instances |
| `CURSOR_DOCS_CHUNK_SIZE` | `1500` | Characters per chunk |
| `CURSOR_DOCS_CHUNK_OVERLAP` | `200` | Overlap between chunks |
| `CURSOR_DOCS_TIMEOUT` | `30000` | Page load timeout (ms) |
| `CURSOR_DOCS_RETRIES` | `3` | Retry attempts per page |

### config/config.exs

```elixir
import Config

config :cursor_docs,
  db_path: System.get_env("CURSOR_DOCS_DB_PATH", "~/.local/share/cursor-docs"),
  browser_pool_size: 3,
  chunk_size: 1500,
  chunk_overlap: 200,
  page_timeout: 30_000,
  max_retries: 3,
  rate_limit: [
    requests_per_second: 2,
    burst: 5
  ]
```

## ğŸ“Š Comparison with Cursor's @docs

| Feature | Cursor @docs | cursor-docs |
|---------|--------------|-------------|
| **Success Rate** | ~50% | **~95%+** |
| **JS Rendering** | âŒ No | âœ… Yes (Playwright) |
| **Error Messages** | âŒ None | âœ… Detailed |
| **Local Storage** | âŒ Server-only | âœ… SurrealDB |
| **Offline Use** | âŒ No | âœ… Yes |
| **Custom Crawl Rules** | âŒ No | âœ… Yes |
| **Rate Limiting** | âŒ Aggressive | âœ… Configurable |
| **P2P Sync** | âŒ No | âœ… Planned |

## ğŸ”„ Scraping Pipeline

```
URL Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. Job Queue (GenServer)                     â”‚
â”‚  - Deduplication                                                â”‚
â”‚  - Priority ordering                                            â”‚
â”‚  - Rate limiting                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2. Browser Pool                              â”‚
â”‚  - Playwright browser instances                                 â”‚
â”‚  - Page lifecycle management                                    â”‚
â”‚  - Resource cleanup                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3. Content Extraction                        â”‚
â”‚  - Wait for JS hydration                                        â”‚
â”‚  - Remove nav/footer/ads                                        â”‚
â”‚  - Extract main content                                         â”‚
â”‚  - Parse metadata (title, description)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    4. Link Discovery                            â”‚
â”‚  - Find internal documentation links                            â”‚
â”‚  - Respect robots.txt                                           â”‚
â”‚  - Apply crawl rules                                            â”‚
â”‚  - Queue discovered URLs                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    5. Chunking                                  â”‚
â”‚  - Split content at paragraph/sentence boundaries               â”‚
â”‚  - Maintain context overlap                                     â”‚
â”‚  - Preserve code blocks                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    6. Storage (SurrealDB)                       â”‚
â”‚  - Store doc_source metadata                                    â”‚
â”‚  - Store doc_chunks with FTS indexing                           â”‚
â”‚  - Update scrape job status                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ MCP Tools

The service exposes these MCP tools:

### `cursor_docs_add`

Add a documentation URL for indexing.

```json
{
  "name": "cursor_docs_add",
  "description": "Add documentation URL to be indexed locally",
  "inputSchema": {
    "type": "object",
    "properties": {
      "url": { "type": "string", "description": "Documentation URL" },
      "name": { "type": "string", "description": "Display name (optional)" },
      "max_pages": { "type": "integer", "description": "Max pages to crawl" }
    },
    "required": ["url"]
  }
}
```

### `cursor_docs_search`

Search indexed documentation.

```json
{
  "name": "cursor_docs_search",
  "description": "Search local documentation index",
  "inputSchema": {
    "type": "object",
    "properties": {
      "query": { "type": "string", "description": "Search query" },
      "limit": { "type": "integer", "default": 5 },
      "sources": { "type": "array", "description": "Filter by source names" }
    },
    "required": ["query"]
  }
}
```

### `cursor_docs_list`

List all indexed documentation sources.

```json
{
  "name": "cursor_docs_list",
  "description": "List all indexed documentation sources",
  "inputSchema": {
    "type": "object",
    "properties": {}
  }
}
```

### `cursor_docs_status`

Get scraping job status.

```json
{
  "name": "cursor_docs_status",
  "description": "Check status of scraping jobs",
  "inputSchema": {
    "type": "object",
    "properties": {
      "source": { "type": "string", "description": "Filter by source" }
    }
  }
}
```

## ğŸ§ª Testing

```bash
# Run all tests
mix test

# Run with coverage
mix test --cover

# Run specific test
mix test test/cursor_docs/scraper/extractor_test.exs
```

## ğŸ“ˆ Roadmap

### v0.1.0 (Current)
- [x] Basic scraping with Playwright
- [x] SurrealDB storage
- [x] Full-text search
- [x] MCP server interface
- [x] CLI commands

### v0.2.0 (Planned)
- [ ] Crawl rules (exclude patterns, max depth)
- [ ] Incremental updates (only re-scrape changed pages)
- [ ] Sitemap.xml support
- [ ] robots.txt respect

### v0.3.0 (Planned)
- [ ] P2P sync between devices
- [ ] Team shared docs
- [ ] Import from Cursor's @docs

### v1.0.0 (Goal)
- [ ] 95%+ success rate on all documentation sites
- [ ] Sub-second search latency
- [ ] Zero-config NixOS service module

## ğŸ”— Related

- [Troubleshooting Guide](../../docs/troubleshooting/DOCS_INDEXING_ISSUE.md)
- [Data Pipeline Control Roadmap](../../docs/internal/DATA_PIPELINE_CONTROL_ROADMAP.md)
- [Cursor's Crawler Repo](https://github.com/getcursor/crawler)

---

*Part of [nixos-cursor](https://github.com/Distracted-E421/nixos-cursor)*

